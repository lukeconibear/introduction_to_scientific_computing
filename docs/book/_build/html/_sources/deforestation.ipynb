{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "identified-studio",
   "metadata": {},
   "source": [
    "# Deforestation tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-friendship",
   "metadata": {},
   "source": [
    "## Global Forest Change 2000-2018 v1.6 data\n",
    "- Download [data](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.6.html).  \n",
    "- First find the cumulative loss over all years.  \n",
    "- Combine mosaic tiles.  \n",
    "- Regrid.  \n",
    "- Find the individual loss for each year.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gdal\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/a68/earlacoa/deforestation/hansen_gfs_v1.6_lossyear/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_mosaic_defor(res, year):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        The Hansen dataset provides the year of forest loss per grid cell between 2000 and 2018.\n",
    "        For each year (e.g. 2005), convert the forest loss to binary by converting all forest loss up to that year\n",
    "        (e.g. 2000-2005) to a 1 and all forest loss in future years to a 0 (e.g. 2006-2018).\n",
    "        This is the cumulative forest loss.\n",
    "        Then to obtain individual forest loss for each year after 2000, subtract the forest loss from the\n",
    "        previous year (e.g. individual 2006 = cumulative 2006 - cumulative 2005).\n",
    "    Args:\n",
    "        res (float): desired resolution in degrees.\n",
    "        year (int): year.\n",
    "    Returns:\n",
    "        hdat (2d array, float): regridded deforestation data.\n",
    "        lat (1d array, float): latitude.\n",
    "        lon (1d array, float): longitude.\n",
    "    \"\"\"\n",
    "    # setup domain\n",
    "    lon_extent_min = -180\n",
    "    lon_extent_max = 180\n",
    "    lat_extent_min = -60\n",
    "    lat_extent_max = 80\n",
    "    scale = int(res / abs(0.00025)) # fixed\n",
    "    ydim = (int((lat_extent_max - lat_extent_min) / res))\n",
    "    xdim1 = (int(10 / res)) # fixed\n",
    "    xdim2 = (int((lon_extent_max - lon_extent_min) / res))\n",
    "    vdat = np.empty((ydim, xdim1))\n",
    "    hdat = np.empty((ydim, xdim2))\n",
    "    fname = ''\n",
    "    j = 0\n",
    "    \n",
    "    for nx in np.arange(-lon_extent_min, -lon_extent_max, -10):\n",
    "        i = 0\n",
    "        \n",
    "        for ny in np.arange(lat_extent_max, lat_extent_min, -10):\n",
    "            # define the filename based on lat and lon as uses north, south, east, and west in filenames\n",
    "            if (nx > 0 or nx == 180) and ny >= 0:\n",
    "                xstr = str(nx).zfill(3)\n",
    "                ystr = str(ny).zfill(2)\n",
    "                fname = 'Hansen_GFC-2018-v1.6_lossyear_' + ystr + 'N_' + xstr + 'W.tif'\n",
    "            elif (nx > 0 or nx == 180) and ny < 0:\n",
    "                xstr = str(nx).zfill(3)\n",
    "                ystr = str(abs(ny)).zfill(2)\n",
    "                fname = 'Hansen_GFC-2018-v1.6_lossyear_' + ystr + 'S_' + xstr + 'W.tif'\n",
    "            elif nx <= 0 and ny >= 0:\n",
    "                xstr = str(abs(nx)).zfill(3)\n",
    "                ystr = str(ny).zfill(2)\n",
    "                fname = 'Hansen_GFC-2018-v1.6_lossyear_' + ystr + 'N_' + xstr + 'E.tif' \n",
    "            elif nx <= 0 and ny < 0:\n",
    "                ystr = str(abs(ny)).zfill(2)\n",
    "                xstr = str(abs(nx)).zfill(3)\n",
    "                fname = 'Hansen_GFC-2018-v1.6_lossyear_' + ystr + 'S_' + xstr + 'E.tif'\n",
    "            print(fname)\n",
    "            \n",
    "            # read data\n",
    "            ds = gdal.Open(path + fname)\n",
    "            band = ds.GetRasterBand(1)\n",
    "            loss_data = band.ReadAsArray()\n",
    "            \n",
    "            # create new lat and lon\n",
    "            gt  = ds.GetGeoTransform()\n",
    "            lon = np.linspace(gt[0], gt[0] + gt[1] * loss_data.shape[1], loss_data.shape[1])\n",
    "            lat = np.linspace(gt[3], gt[3] + gt[5] * loss_data.shape[0], loss_data.shape[0])\n",
    "            xx, yy = lon[::scale], lat[::scale] \n",
    "            \n",
    "            # transform to binary for the year of interest\n",
    "            loss_data[loss_data > (year - 2000)] = 0\n",
    "            loss_data[(loss_data >= 1) & (loss_data <= (year - 2000))] = 1\n",
    "            \n",
    "            # equate coarse grid to high-res grid\n",
    "            data_regrid = np.zeros((xdim1, xdim1))\n",
    "            \n",
    "            for ix in range(len(xx)):\n",
    "                temp_lon_ix = np.where((lon == xx[ix]))[0]\n",
    "                \n",
    "                for iy in range(len(yy)):                   \n",
    "                    temp_lat_iy = np.where((lat == yy[iy]))[0]\n",
    "                    \n",
    "                    # trim the data\n",
    "                    data_trim = (loss_data[temp_lat_iy[0]:temp_lat_iy[0] + scale, :][:, temp_lon_ix[0]:temp_lon_ix[0] + scale])\n",
    "                    \n",
    "                    # find average across this trimmed data\n",
    "                    mean_loss = np.nanmean(data_trim)\n",
    "                    \n",
    "                    # set this mean to the corresponding value on the coarser grid\n",
    "                    data_regrid[iy, ix] = mean_loss\n",
    "                    \n",
    "            # add each tiles' regridded data to a new global data\n",
    "            vdat[i * xdim1:(i + 1) * xdim1, :] = data_regrid\n",
    "            i += 1\n",
    "            \n",
    "        hdat[:, j * xdim1:(j + 1) * xdim1] = vdat\n",
    "        j += 1\n",
    "        \n",
    "    # create final global lat and lon\n",
    "    lat = np.arange(lat_extent_max, lat_extent_min, -res)\n",
    "    lon = np.arange(lon_extent_min, lon_extent_max, res)\n",
    "    \n",
    "    return hdat, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(defor_xx, defor_yy, defor_array, year, values_max, label):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Create a contoured plot of the global deforestation.\n",
    "        Either cumulatively or individually per year.\n",
    "    Args:\n",
    "        defor_xx (2d array, float): longitude.\n",
    "        defor_yy (2d array, float): latitude.\n",
    "        defor_array (2d array, float): deforestation.\n",
    "        year (int): year.\n",
    "        values_max (float): maximum value for the colour bar.\n",
    "        label (str): cumulative or individual.\n",
    "    Returns:\n",
    "        Plot displayed and saved to file.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(1, figsize=(14, 7))\n",
    "    gs = gridspec.GridSpec(1, 1)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    basemap = Basemap(\n",
    "        llcrnrlon=-180, llcrnrlat=-90, urcrnrlon=180, urcrnrlat=90,\n",
    "        projection='cyl', resolution='l'\n",
    "    )\n",
    "    basemap.drawcountries(linewidth=0.2)\n",
    "    basemap.drawcoastlines(linewidth=0.2)\n",
    "    basemap.fillcontinents(color='lightgrey', zorder=0)\n",
    "    basemap.drawparallels(np.arange(-80., 81., 10.), labels=[1, 0, 0, 0], fontsize=14, linewidth=0)\n",
    "    basemap.drawmeridians(np.arange(-180., 181., 30.), labels=[0, 0, 0, 1], fontsize=14, linewidth=0)\n",
    "    cmap = 'viridis'\n",
    "    norm = colors.Normalize(vmin=0, vmax=values_max)\n",
    "    im = basemap.contourf(\n",
    "        defor_xx, defor_yy, defor_array, \n",
    "        np.linspace(0, values_max, 11), cmap=cmap, norm=norm\n",
    "    )\n",
    "    sm = plt.cm.ScalarMappable(norm=norm, cmap=im.cmap)\n",
    "    sm.set_array([])\n",
    "    cb = basemap.colorbar(sm, \"right\", size=\"5%\", pad='2%', norm=norm, cmap=cmap, ticks=im.levels)\n",
    "    cb.set_label(\n",
    "        'Hansen GFC 2018 v1.6, loss year, 0.25 degrees,\\n fractional deforestation (0-1)', \n",
    "        size=14\n",
    "    )\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title(str(year), size=16)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    plt.savefig(\n",
    "        path + 'Hansen_GFC-2018-v1.6_lossyear-' + label + '_global_0.25deg_' + str(year) + '.png', \n",
    "        dpi=200, alpha=True, bbox_inches='tight'\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.linspace(2000, 2018, 19, dtype=int)\n",
    "res = 0.25\n",
    "defor_cumulative = {}\n",
    "defor_individual = {}\n",
    "\n",
    "for year in years:\n",
    "    # run regridding and mosaicing function\n",
    "    output, lat, lon = regrid_mosaic_defor(res, year)\n",
    "\n",
    "    # create dataarray\n",
    "    defor = xr.DataArray(\n",
    "        data = output, \n",
    "        coords = [lat, lon],\n",
    "        dims = ['lat', 'lon']\n",
    "    )\n",
    "    defor.name = 'deforestation'\n",
    "    defor = defor.assign_coords({'time': datetime.strptime(str(year)[-2:], '%y')})\n",
    "    defor = defor.expand_dims('time')\n",
    "    defor.to_netcdf(path + 'Hansen_GFC-2018-v1.6_lossyear-cumulative_global_0.25deg_' + str(year) + '.nc')\n",
    "\n",
    "    defor_array = defor.isel(time=0).values\n",
    "    defor_xx, defor_yy = np.meshgrid(defor.lon.values, defor.lat.values)\n",
    "    \n",
    "    # plot cumulative\n",
    "    plot(defor_xx, defor_yy, defor_array, year, 1, 'cumulative')\n",
    "    \n",
    "    # calculate individual yearly loss\n",
    "    defor_cumulative.update({year: xr.open_dataset(\n",
    "        path + 'Hansen_GFC-2018-v1.6_lossyear-cumulative_global_' + str(res) + 'deg_' + str(year) + '.nc'\n",
    "    )['deforestation']})\n",
    "    if year == 2000:\n",
    "        pass\n",
    "    else:\n",
    "        defor_individual.update({\n",
    "            year: defor_cumulative[year] - defor_cumulative[year - 1]\n",
    "        })\n",
    "    \n",
    "    defor_individual[year].to_netcdf(\n",
    "        path + 'Hansen_GFC-2018-v1.6_lossyear-individual_global_' + str(res) + 'deg_' + str(year) + '.nc'\n",
    "    )\n",
    "    \n",
    "    # plot individual\n",
    "    defor_array = defor_individual[year].isel(time=0).values\n",
    "    plot(defor_xx, defor_yy, defor_array, year, 0.5, 'individual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-credit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
